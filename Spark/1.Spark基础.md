# Spark基础

## 什么是spark

Spark和MapReduce，Tez一样是一个集群计算引擎，具有快速，可扩展，以及通用三个优势，具体可以查看官网~


## Spark组成

Spark由三部分组成

- 集群管理器
- Spark Core
- SparkSql, SparkStreaming, Spark MLlib 以及 Spark GraghX
  
## Spark的运行模式

### Spark常用概念

- Master:类似于hadoop的RM,负责整个集群的资源调度，其主要功能有监听Worker，以及接收client提交的application，并将application分发给各个Worker
- Worker:掌握该进程所在的slave的资源信息，类似于NM,Master和Worker是一台机器上的守护线程
- driver program：驱动程序，其包含有Spark程序的主函数，定义了RDD,再spark中可以通过SparkContext对它进行访问
- executor：执行器是每个节点上的执行器。用于执行分配的计算任务以及为节点存储数据
- RDDs：弹性分布式数据集，RDD是弹性分布式数据集
- cluster managers：为了在一个 Spark 集群上运行计算, SparkContext对象可以连接到几种集群管理器.集群管理器负责跨应用程序分配资源 

### Local模式

下载spark后，解压即可使用，该模式下通过 --master local[n] 指定核心数来模拟并行运算

### standalone

Hadoop可以自己构建一个由Master+Slave构成的Spark集群。

配置Standalone需要配置spark-evn.sh以及slvaes，让后将配置好的spark程序分发。

### Yarn 

配置yarn配置spark-evn.sh添加`YARN_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop`即可

## 其他配置

### HA

### 历史服务器配置

