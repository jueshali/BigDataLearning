# 分区器

## HashPartition
获取hash值对分区数取余获取所在区的index，容易造成数据倾斜

## RangerPartition

将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。

RangerPartition要求数据一定能够排序。

- 获取一个rangeBounds的数组，通过蓄水池算法获取
- 对这个rangeBounds排序后
- 对于任意一个元素就可以确定其分区

## 自定义分区器
混入Partitioner，实现两个方法

```scala
package cn.lpc.RDD.Partitioner

import org.apache.spark.rdd.RDD
import org.apache.spark.{HashPartitioner, Partitioner, SparkConf, SparkContext}

object MyPartition {
    def main(args: Array[String]): Unit = {
        val conf: SparkConf = new SparkConf().setMaster("local[2]").setAppName("CreateRDD")
        val sc = new SparkContext(conf)
        var rdd = sc.parallelize(Array((1, "a"), (1, "b"), (2, "c"),(4,"d")))
        // sortByKey 里面new了一个rangePartitioner,所以会触发一次collect
        rdd.sortByKey()
        val rdd1: RDD[(Int, String)] = rdd.partitionBy(new MyPartition(2))
        rdd1.zipWithIndex().collect().foreach(println)
    }
}

class MyPartition(val numP: Int) extends Partitioner{
    override def numPartitions: Int = numP

    override def getPartition(key: Any): Int =key match{
        case null => 0
        case _ =>key.hashCode().abs % numPartitions
    }

    // 以下两个方法的实现可以提高效率，可以防止重新分区，在多次分区时会如果发现两个分区器一致会不在分区
    override def equals(other: Any): Boolean = other match {
        case h: MyPartition =>
            h.numPartitions == numPartitions
        case _ =>
            false
    }

    override def hashCode: Int = numPartitions
}

```