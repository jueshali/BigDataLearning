# Flink算子
1. 基本转换算子：将会作用在数据流中的每一条单独的数据上。

2. KeyedStream转换算子：在数据有key的情况下，对数据应用转换算子。

3. 多流转换算子：合并多条流为一条流或者将一条流分割为多条流。

4. 分布式转换算子：将重新组织流里面的事件。

## 基本转换算子

基本转换算子可以将一个event中的内容转换.是一个流到另外一个流,包括Map,flatMap,filter三个转换算子.功能就不详谈了.

## 键控流转换算子(key value)
DataStream API提供了一个叫做KeyedStream的抽象，此抽象会从逻辑上对DataStream进行分区，分区后的数据拥有同样的Key值，分区后的流互不相关。意思就是在原有数据上继续封装了一个key.`(Person)-->(key,(Person))`

## 多流转换算子
将多个流合在一起,实际上还是一个一个的event.例如union.Split是Union的反操作

还有connect.DataStream.connect()方法接收一条DataStream，然后返回一个ConnectedStreams类型的对象，这个对象表示了两条连接的流。ConnectedStreams提供了map()和flatMap()方法，分别需要接收类型为CoMapFunction和CoFlatMapFunction的参数。以上两个函数里面的泛型是第一条流的事件类型和第二条流的事件类型，以及输出流的事件类型。还定义了两个方法，每一个方法针对一条流来调用。`map1()`和`flatMap1()`会调用在第一条流的元素上面，`map2()`和`flatMap2()`会调用在第二条流的元素上面。

## 分布式转换算子
当我们使用DataStream API来编写程序时，系统将自动的选择数据分区策略，然后根据操作符的语义和设置的并行度将数据路由到正确的地方去.针对DataStream才有.
broadcast()方法将输入流的所有数据复制并发送到下游算子的所有并行任务中去。
custom():自定义

## Flink类型(scala)
基本数据类型加上样例类,还有就是Array, ArrayList, HashMap, Hadoop Writable types, Option, Try
